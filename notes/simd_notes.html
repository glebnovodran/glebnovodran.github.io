<!doctype html>
<html lang="en-us">

<head>
	<meta charset="utf-8">
	<meta http-equiv="Content-Type" content="text/html; charset=utf-8">
	<meta http-equiv="Cache-Control" content="no-cache, no-store, must-revalidate">
	<meta http-equiv="Pragma" content="no-cache">
	<meta http-equiv="Expires" content="0">
	<link rel="shortcut icon" href="favicon.ico">
	<title>SIMD notes</title>
	<link rel="stylesheet" href="notes.css" />
</head>

<body>
	<table id="main_text"><tr><td>
		<!-- text start -->
		<div class="header_text">&#x270D; WebAssembly SIMD in <a href="https://github.com/glebnovodran/ostinato">Ostinato</a>.</div>
		<hr/>
		<p>
			<a href="perf_ostinato.html">Examining</a> Webassembly performance in different browsers on variouos platforms at the moment suggests that a SIMD-enabled version do not exhibits any distinct speed improvement.
		</p>
		<p>
			In the 'precise' mode the matrix multiplication routine cxMtx::mul is called about 1500 times per frame.
			Supposedly, even a small improvement in its performance would result in some noticeable speed-up.
			This observation is relevant to the game-specific workload only. I.e.the matrices are getting multiplied often, but those are small 4x4 matrices typical in this context.
			The situation could be quite different for matrices of significantly bigger sizes.
		</p>
		<p>The difference between the native versions compiled with and without SIMD instructions enabled is marginal, but a tiny improvement is present.</p>
		<p>Nethertheless, it is interesting to take a look at the code clang creates for this demo and to compare the 'vectorized' version with the 'scalar' one.</p>

		<p>First we need to produce a web-version with the assembly code that is not embedded into the page.</p>
		<p>This is how to do it enabling SIMD vectorization:</p>
		<code>
			./build.sh wasm-0 -g -msimd128
		</code>
		<p>Without vectorization enabled:</p>
		<code>
			./build.sh wasm-0 -g
		</code>
		<p>Extract the listing with:</p>
		<code>
			$EMSDK/upstream/bin/wasm-dis bin/ostinato.wasm > ostinato_wasm.txt
		</code>
		<br/>
		<p>Native build with SIMD code generation enabled:</p>
		<code>
			CXX=clang++ ./build.sh -O3 -march=native
		</code>
		<p>And without SIMD code generation:</p>
		<code>
			CXX=clang++ ./build.sh -O3 -march=native -fno-tree-vectorize -fno-tree-slp-vectorize
		</code>
		<p>It could be interesting to investigate the code produced by building with <b>XD_XMTX_CONCAT_VEC</b> and <b>XD_USE_LA</b> flags</p>
		<p><b>XD_XMTX_CONCAT_VEC</b> allows to choose an xt_xmtx (3x4 transformation matrix) concatenation implementation:</p>
		<p>By default it is XD_XMTX_CONCAT_VEC=0 - a 'direct' implementaion without loops.<br/>
		Specifying XD_XMTX_CONCAT_VEC=1|2 will choose an implementation with loops that hints compilers to use SIMD instructions.<br/>
		XD_XMTX_CONCAT_VEC=2 can be useful if compiling for architectures supporting 512 bit operations (for example avx+).<br/></p>

		<code>CXX=clang++ ./build.sh ... -DXD_XMTX_CONCAT_VEC=0|1|2</code>
		<p>
			<a href="https://github.com/schaban/crosscore_dev/">Crosscore</a> contains a set of templates for linear algebra operations.
			By default 4x4 matrix operations, such as multiplication, vector/point trasnformation and matrix inversion, make use of them.
			<b>XD_USE_LA</b> allows swith this off. 
			<br/>
				XD_USE_LA=0 - don't use LA templates; default Cramer's matrix inversion;<br/>
				XD_USE_LA=1 - use LA templates; matrix inversion using Gauss-Jordan method
		</p>
		<code>CXX=clang++ ./build.sh ... -DXD_USE_LA=0|1</code>

		<p>To extract the listing:</p>
		<code>
			objdump -CD -j .text bin/prog/ostinato > ostinato_native.txt
		</code>
		<!-- text end -->
		<br/>
	</td></tr></table>
</body>

</html>

